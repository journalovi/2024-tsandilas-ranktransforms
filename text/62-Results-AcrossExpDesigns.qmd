### Type I errors across experimental designs {#extra}
Our third experiment investigates the generalizability of the aforementioned results to other experimental designs involving two or three factors. We assess five out of the six ratio scales examined earlier. We exclude the Cauchy distribution and replace it by a 5-level ordinal scale with flexible thresholds.

**Main effects**. @fig-designs-main illustrates Type I errors for the main effect of $X_2$ while varying the magnitude of the main effect of $X_1$, with a focus on $n = 20$. Across all cases, RNK and INT consistently maintain error rates close to $5\%$. PAR's error rate remains overall close to $5\%$ but reaches notably low levels for specific combinations of designs ($2 \times 2 \times 2$ and $3 \times 3 \times 3$ repeated-measures) and distributions (log-normal and exponential). In contrast, ART inflates error rates for all non-normal distributions, with discrepancies across different designs. We observe that ART is particularly problematic in discrete distributions when applied to the $2 \times 2 \times 2$ and $3 \times 3 \times 3$ designs.

::: {#fig-designs-main}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix <- "3_test-Designs"
alpha = 0.05

distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert5B")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")

df <- readData(prefix, n = 20, alpha, effectType = 1, distributions)
df <- reshapeByDesign(df, dnames)

plotlyErrorByDesign(df, xlab = "magnitude of main effect", var = "rateX2", xvar = "effectX1", max = 62)
```
Type I error rates ($\alpha = .05$) for the **main effect of $X_2$** as a function of the magnitude $a_1$ of the main effect of $X_1$ ($n = 20$)
:::

We provide additional results for the between-subjects design in @fig-2x3-main, where we vary the effect of $X_2$ and measure Type I error rates on $X_1$. ART's error rates for the three discrete distributions appear higher than those observed in @fig-designs-main, indicating a potential dependence on the number of levels of the factors. Again, we observe a consistent trend where error rates increase with the sample size.

::: {#fig-2x3-main}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix2 <- "3_test-Designs_2x3"

df2x3 <- readlyData2(prefix2, alpha, effectType = 2, distributions, dnames)

plotlyError(df2x3, xlab = "magnitude of main effect", var = "rateX1", xvar = "effectX2", max = 62)
```
Additional results for the $2 \times 3$ between-subjects design, where we measure Type I error rates ($\alpha = .05$) for the **main effect of $X_1$.** We now vary the magnitude $a_2$ of the main effect of $X_2$.
:::

**Interaction effects**. @fig-designs-interaction-1 displays Type I error rates for the interaction effect $X_1 \times X_2$ while varying the effect of $X_1$ ($n = 20$). We observe consistent trends in line with our previous findings. For additional insights, we direct readers to our raw experimental data, which demonstrate that these trends persist across other interaction terms, namely $X_1 \times X_3$, $X_2 \times X_3$, and $X_1 \times X_2 \times X_3$, within the two 3-factor designs.

::: {#fig-designs-interaction-1}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
plotlyErrorByDesign(df, xlab = "magnitude of main effect", var = "rateX1X2", xvar = "effectX1", max = 62)
```
Type I error rates ($\alpha = .05$) for the **interaction** $X_1 \times X_2$ as a function of the magnitude $a_1$ of the main effect of $X_1$ ($n = 20$) 
:::

Our results in @fig-designs-interaction-2 confirm that all methods exhibit varying degrees of difficulty in accurately inferring interaction effects when main effects are present on all interacting factors. While PAR and ART perform well for normal distributions, their error rates escalate more rapidly across all other distributions. ART's error rates become exceptionally low for certain designs (e.g., $2 \times 3$ and $2 \times 2 \times 2$), suggesting a challenge in detecting small interaction effects when main effects are large. RNK exhibits a similar pattern for the $2 \times 2 \times 2$ design. Notably, both methods display high error rates under ordinal and binomial scales, although these rates are lower compared to those of PAR and ART.

::: {#fig-designs-interaction-2}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert5B")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")

df <- readData(prefix, n = 20, alpha, effectType = 0, distributions)
df <- reshapeByDesign(df, dnames)
plotlyErrorByDesign(df, xlab = "magnitude of main effects", var = "rateX1X2", xvar = "effectX1", max = 105)
```
Type I error rates ($\alpha = .05$) for the **interaction** $X_1 \times X_2$ as a function of the magnitudes $a_1 = a_2$ of the main effects of $X_1$ and $X_2$  ($n = 20$)
:::
