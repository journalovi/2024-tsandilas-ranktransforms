### Effect size estimates {#effect-sizes}
Our final experiment assesses the precision of the effect size estimates (Cohen's $f$) of each method. 

**Main effects**. We first evaluate estimates of the main effect of $X_1$ as the magnitude of the two main effects varies. @fig-effect-main-scatterplots-1 illustrates the relationship between the Cohen's $f$ obtained with each method and the $f$ of the ground-truth method, when $a_1$ and $a_2$ vary within the range $[-2, 2]$. The proximity of data points to the black diagonal indicates the closeness of estimates to the ground truth. Points above the line are likely to overestimate the effect size, while points under the line are likely to underestimate it. 

::: {#fig-effect-main-scatterplots-1}
```{r, echo=FALSE, fig.height=3.4, message=FALSE, warning=FALSE}
source("effect_sizes_scatterplots.R")
prefix <- "6_scatter-Effect_Size-g2"
df <- readlyDataPoints(prefix,  distributions=c("norm", "lnorm", "likert5B"), dnames = c("Normal", "Log-normal", "Ordinal (5 levels)")) %>% toCohensf()
fig <- plotlyScatter(df, xlab = "Ground truth", ylab= "Cohen's f", xvar = "fX1", max = 1.05)

fig
```
Scatterplots showing the relationship between effect size estimates (Cohen's $f$) of each method and estimates of the ground-truth method for the main effect of $X_1$, when $a_1$ and $a_2$ vary within the range $[-2, 2]$. 
:::

We observe that PAR tends to underestimate effect sizes under log-normal distributions, in consistency with its low power (see @fig-power-main-1). ART's estimates are instead spread across both sides. We invite the reader to zoom in on the lower range of values ($f < 0.4$), where the method frequently exagerates effects. INT demonstrates the highest precision, followed by RNK. However, their performance deteriorates under the ordinal scale. Still, ART performs worse than all other methods.

@fig-effect-main-scatterplots-2 shows the same relationship but for a larger range of effects $[-8, 8]$. We observe that all three rank-based methods struggle to detect large effects, even when the underlying distribution is normal. Interestingly, INT's performance declines when Cohen's $f$ exceeds a certain level. For the ordinal distribution, estimates are extremely noisy across all methods. We emphasize, however, that this is at least partly due to the low precision of the ordinal scale itself, since its five discrete levels cannot capture the full range of variations of the latent variable. The fact that all methods underestimate large effects can be simply explained by the limited range of the ordinal scale's extremes.

::: {#fig-effect-main-scatterplots-2}
```{r, echo=FALSE, fig.height=3.4, message=FALSE, warning=FALSE}
#source("effect_sizes_scatterplots.R")
prefix <- "6_scatter-Effect_Size-g8"

df <- readlyDataPoints(prefix,  distributions=c("norm", "lnorm", "likert5B"), dnames = c("Normal", "Log-normal", "Ordinal (5 levels)")) %>% toCohensf()
fig <- plotlyScatter(df, xlab = "Ground truth", ylab= "Cohen's f", xvar = "fX1", max = 4.05)

fig
```
Scatterplots showing the relationship between effect size estimates (Cohen's $f$) of each method and estimates of the ground-truth method for the main effect of $X_1$, when $a_1$ and $a_2$ vary within the range $[-8, 8]$. 
:::

To systematically evaluate the precision of effect size estimates across different methods, we employ the coefficient of determination, denoted as $R^2$ ($R$ squared). This metric quantifies the proportion of variation in the $f$ estimates of each method that is predictable from the estimate provided by the reference method, considered as the ground truth. We compute $R^2$ over 1000 iterations. Within each iteration, we randomly sample the magnitude of the two main effects ($a_1$ and $a_2$) from a range spanning $[-g, g]$, where $g$ takes values from the set ${0, 0.5, 1, 2, 4, 8}$. It is worth noting that the $R^2$ measure assesses the proximity of estimates to the ground truth, without distinguishing between underestimates and overestimates. We present these results based on a sample size of $n=20$.

@fig-effect-main-1 depicts trends for the first factor $X_1$. INT performs exceptionally well across all continuous distributions, but its precision declines when the range of effects becomes large ($g > 4$). PAR's performance is strikingly low under the log-normal distribution and, to a lesser degree, under the exponential distribution. ART emerges as the second-worst method for these distributions. Finally, we observe low $R^2$ values for all methods under the binomial and ordinal distributions. ART's performance is particularly problematic when effects sizes are low.  

::: {#fig-effect-main-1}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix <- "6_test-Effect-Size-Main"
distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert5B")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")

df <- readData(prefix, n = 20, alpha= NA, effectType = -1, distributions)

df <- df %>% arrange(design,distr,effectX1,cohensfX1)  %>% group_by(design,distr,effectX1)
df <- as.data.frame(df) %>% reshapeByDesign(dnames, effectvars = c("effectX1","effectX2","effectX1X2"), groupvars = c("distr","method","n"))

#df <- reshapeByDesign(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))
plotlyErrorByDesign2(df, xlab = "range of effects (g)", var = "cohensfX1", xvar = "effectX1", min = -11, max = 103, ytitle = 'R squared')
```
$R^2$ scores measuring the relationship between effect size estimates (Cohen's $f$) of each method and estimates of the ground-truth method for the main effect on $X_1$. We express these scores as a function of the range of the magnitude of effects $g$.
:::


**Interaction effects**. We extend our analysis to examine trends regarding the interaction effect, as depicted in Figure @fig-effect-interaction. We now also vary $a_{12}$ within the same range $[-g, g]$. $R^2$ approaches zero or becomes negative under certain conditions, indicating that effect size estimates cannot be trusted in these cases. RNK and INT emerge as the most precise methods under non-normal distributions, but their performance declines rapidly when $g > 2$. Finally, PAR outperforms ART across all discrete distributions, as well as the normal distribution. 

::: {#fig-effect-interaction}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix <- "6_test-Effect-Size"
distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert5B")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")

df <- readData(prefix, n = 20, alpha= NA, effectType = -1, distributions)

df <- df %>% arrange(design,distr,effectX1X2,cohensfX1X2)  %>% group_by(design,distr,effectX1X2)
df <- as.data.frame(df) %>% reshapeByDesign(dnames, effectvars = c("effectX1","effectX2","effectX1X2"), groupvars = c("distr","method","n"))

#df <- reshapeByDesign(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))
plotlyErrorByDesign2(df, xlab = "range of effects (g)", var = "cohensfX1X2", xvar = "effectX1X2", min = -51, max = 105, ytitle = 'R squared')
```
$R^2$ scores measuring the relationship between effect size estimates (Cohen's $f$) of each method and estimates of the ground truth method for the interaction effect $X_1 \times X_2$. We express these scores as a function of the range of the magnitude of effects $g$.
:::